---
title: 【云存储平台搭建_01】MinIO集群部署+ngnix负载均衡
categories: 云存储平台搭建
tags:
  - MinIO
  - centos7
  - ngnix
excerpt: MinIO集群部署+ngnix负载均衡
date: 2021-01-25 20:33:36
img: '/images/minio/minio_logo.jpg'
---



## MinIO集群部署+ngnix负载均衡

官方文档：[https://docs.min.io/cn/](https://docs.min.io/cn/)
参考文章1：[https://zhuanlan.zhihu.com/p/155844469](https://zhuanlan.zhihu.com/p/155844469)
参考文章2：[https://www.jianshu.com/p/c2b43ff67df0](https://www.jianshu.com/p/c2b43ff67df0)
MinIO 是一个基于Apache License v2.0开源协议的对象存储服务。它兼容亚马逊S3云存储服务接口，非常适合于存储大容量非结构化的数据，例如图片、视频、日志文件、备份数据和容器/虚拟机镜像等，而一个对象文件可以是任意大小，从几kb到最大5T不等。

MinIO是一个非常轻量的服务,可以很简单的和其他应用的结合，类似 NodeJS, Redis 或者 MySQL。

###  一：MinIO分布式好处

**数据保护**
分布式Minio采用` 纠删码`来防范多个节点宕机和位衰减bit rot。

分布式Minio`至少需要4个硬盘`，使用分布式Minio自动引入了纠删码功能。

**高可用**
单机Minio服务存在`单点故障`，相反，如果是一个有 m 台服务器， n 块硬盘的分布式Minio,只要有 m/2 台服务器或者 m*n/2 及更多硬盘在线，你的数据就是安全的。

例如，一个`16节点`的Minio集群，每个节点200块硬盘，就算`8台服務器`宕机，即大概有`1600块硬盘`，这个集群仍然是可读的，不过你需要`9台服務器`在线才能写数据。

你还可以使用存储类型自定义每个对象的奇偶分布。

**一致性**
Minio在分布式和单机模式下，所有读写操作都严格遵守`read-after-write`和l`ist-after-write`一致性模型。

### 二：minio基本原理

#### 2.1 名词

**Object**：存储到 Minio 的基本对象，如文件、字节流，Anything...

**Bucket**：用来存储 Object 的逻辑空间。每个 Bucket 之间的数据是相互隔离的。

**Drive**：部署 Minio 时设置的磁盘，Minio 中所有的对象数据都会存储在 Drive 里。

**Set**：一组 Drive 的集合，Minio 会自动根据 Drive 数量，将若干 Drive 划分为多个 Set（For example: {1...64} is divided into 4 sets each of size 16.）

**DataDrives** ：纠删码中的数据盘，用来存储 Object 原始数据。

**ParityDrives**：纠删码中的冗余盘，用来存储 Object 计算出来的冗余数据。

####  2.2 上传对象过程

分布式模式下，上传文件的最终实现在 xlObjects.putObject（） 中。xlObjects 就是前面提到的 Set，xlObjects.putObject（）会将上传的文件存储到 Set 下的每个 Drive 中。下面我们就来分析下我们上传的文件，究竟是怎么上传到 Drive 下的。

##### 2.2.1 划分 DataDrives & ParityDrives

文件上传的第一步，就是将 Set 下的所有 Drives 划分为 dataDrives 和 parityDrives。
Minio 纠删码的默认配置为 1 : 1，即数据盘和冗余盘个数相同，所以我们真正可用的存储空间，只有我们总空间的一半大小。

##### 2.2.2  划分 Blocks

对于上传的 Object，Minio 会将其划分为多个 Block 来计算纠删码。

- 如果 Object Size > 10 MB，那么每个 block 的大小就是 10 MB。
- 如果 Object Size < 10 MB，如果也划分一个 10 MB 的 block 就太浪费空间了，所以分配一个大小刚好为 Object Size 的 block 就够了。

##### 2.2.3  读取 Object 上传流

读取上传流逻辑在 Erasure.Encode（）中Minio 会串行从上传流中读取数据，填到一个 Buffer 中，Buffer 的大小刚好为 2.2 确定的 Block 大小。

##### 2.2.4  纠删码编码

每读取一块 Block，Minio 就会对其进行纠删码编码，生成 data shards 和 parity shards。 编码逻辑在Erasure.EncodeData（）中。

因为一个 Set 中有多个 Drive（DataDrives + ParityDrives），所以 Minio 会先将一块 Block 按照 Drives 数量，划分为多个小块，这些小块在 Minio 中叫做 Shards。比如一个 Block 是 10MB， 而 Set 里有 16 个 Drive（8 DataDrives + 8 ParityDrives），此时 Minio 会将 Block 按照 10 MB / 8 DataDrives 的方式，将数据划分到 8 个 Data Shards，并额外再创建 8 个 空 Shards，用来存储编码后的冗余数据

接着 Minio 就会对 Data Shards 进行纠删码编码，并将编码后的冗余数据存储到前面创建的 8 个空 Shards 中，也就是 parity shards 中。

##### 2.2.5  数据落盘

经过 2.4 的编码之后，我们得到了 Block 最终需要落盘的数据。

落盘的逻辑在 parallelWriter.Write（）中。parallelWriter 看名字就知道，是并行 Writer。不过parallelWriter 本身并不直接写数据，它只是多个 writer 的一个并行封装。

```go
	for i := range p.writers {
		if p.writers[i] == nil {
			p.errs[i] = errDiskNotFound
			continue
		}

		wg.Add(1)
		go func(i int) {
			defer wg.Done()
			_, p.errs[i] = p.writers[i].Write(blocks[i])
			if p.errs[i] != nil {
				p.writers[i] = nil
			}
		}(i)
	}
```

如上所示，parallelWriter 为每个 writer 分配了一个 block（注意，这里的 block 其实是上面所说的 shard），并为每个 writer 开启一个协程，并行写入数据。

那么这里的 writer 是什么呢？就是 minio 的每个磁盘的 writer。对于每块磁盘，minio 都会封装一个 writer 用来写入数据。

**minio 除了用纠删码来保护数据，还采用了 Bitrot 技术。**

> Bitrot 是指位衰减，是指存储在存储介质中的数据的性能和完整性的缓慢恶化。它也被称为比特衰变、数据腐烂、数据衰变和静默数据损坏。

可以说纠删码是用来保证 Object 的每个 Block 的数据正确和可恢复的，而 Bitrot 技术是用来检验磁盘数据的正确性的。

纠删码技术比较复杂，但是 Bitrot 技术就比较简单了，具体逻辑在 streamingBitrotWriter 中。本质就是在写数据之前，先计算好数据的 hash，然后将 hash 先写入磁盘，再写入需要存储的数据。这样读取数据时，就可以通过重新计算 hash，和原始写入的 hash进行一致性比较，来判断数据是否有损坏。

上传文件时，Minio 不是直接上传到 object 在磁盘的最终存储目录的，而是先写到一个临时目录，等所有数据都写到临时目录后，Minio 才会进行 rename 操作，将 object 数据存储到最终存储目录。

##### 2.2.6 Meta 数据落盘

除了 Object 数据，Minio 还会针对 object 生成 meta 数据，并以 json 格式，存储到每个磁盘下（和 Object 数据同一目录）。Meta 格式如下：

```go
// A xlMetaV1 represents `xl.json` metadata header.
type xlMetaV1 struct {
	Version string   `json:"version"` // Version of the current `xl.json`.
	Format  string   `json:"format"`  // Format of the current `xl.json`.
	Stat    statInfo `json:"stat"`    // Stat of the current object `xl.json`.
	// Erasure coded info for the current object `xl.json`.
	Erasure ErasureInfo `json:"erasure"`
	// MinIO release tag for current object `xl.json`.
	Minio struct {
		Release string `json:"release"`
	} `json:"minio"`
	// Metadata map for current object `xl.json`.
	Meta map[string]string `json:"meta,omitempty"`
	// Captures all the individual object `xl.json`.
	Parts []ObjectPartInfo `json:"parts,omitempty"`
}
```

### 三：整体存储结构

经过上面的分析，我们对 Minio 上传逻辑应该有所了解了，下面我们来看看文件经过上传后，最终的存储结构，以 16 个磁盘为例。

![img](https://pic4.zhimg.com/80/v2-6b3d20d92f0434090edade7b7beea9bb_1440w.jpg)

可以看见文件（Flink基础教程.pdf）上传到 Minio 后，被存储到 16 个 drive 下面了。part.1 即为 object 数据。在数据盘中，part.1 为 object 原始数据，而在冗余盘中，part.1 为 object 纠删码的编码数据。当然对于 Drive 来说，它根本不关心它存储的是什么。

![img](https://pic1.zhimg.com/80/v2-4515d8084b592b87684d9523ad8e0a58_1440w.jpg)



### 四：开始搭建

#### 4.1 服务规划

| ID   | IP           | HOST-NAME    | DISCRIPTION   |
| :--- | :----------- | :----------- | :------------ |
| 1    | 192.168.75.3 | minio-node-1 | minio节点01   |
| 2    | 192.168.75.4 | minio-node-2 | minio节点02   |
| 3    | 192.168.75.5 | minio-node-3 | minio节点03   |
| 4    | 192.168.75.6 | minio-nginx  | ngnix负载均衡 |

##### 4.1.1 设置hostname

在每一个节点上分别执行以下命令，设置hostname。

```shell
# 192.168.75.3
sudo hostnamectl set-hostname minio-node-1
# 192.168.75.4
sudo hostnamectl set-hostname minio-node-2
# 192.168.75.5
sudo hostnamectl set-hostname minio-node-3
# 192.168.75.6
sudo hostnamectl set-hostname minio-ngnix
```

##### 5.1.2 设置端口联系

在每一个minio节点上执行以下命令，设置端口间联系

```shell
cat >> /etc/hosts <<EOF
192.168.75.3   minio-node-1
192.168.75.4   minio-node-2
192.168.75.5   minio-node-3
EOF
```

#### 4.2 MinIO下载安装

在每一个minio节点上执行以下操作，每个节点创建创建两个盘，下载minio二进制文件，并设置权限。

```
mkdir -p /root/minio  /root/minio/{data1,data2}  /etc/minio
cd  /root/minio
wget http://dl.minio.org.cn/server/minio/release/linux-amd64/minio
chmod +x minio
```

##### 4.2.1  编写运行脚本

在每一个minio节点上执行以下操作

```
vim /root/minio/run.sh
```

输入以下内容，用于设置minio用户名密码，集群配置

```
export MINIO_ROOT_USER=minioadmin
export MINIO_ROOT_PASSWORD=minioadmin
/root/minio/minio server --config-dir /etc/minio --address :9000  http://minio-node-{1...3}/root/minio/data{1...2}
```

#####  4.2.2 服务化配置

在每一个minio节点上创建/usr/lib/systemd/system/minio.service文件，进行服务化配置

```
cat > /usr/lib/systemd/system/minio.service <<EOF
[Unit]
Description=Minio
Documentation=https://docs.minio.io/

[Service]
WorkingDirectory=/root/minio/
ExecStart=/root/minio/run.sh

StandardOutput=journal
StandardError=inherit


# Disable timeout logic and wait until process is stopped
TimeoutStopSec=0

# SIGTERM signal is used to stop Minio
KillSignal=SIGTERM

SendSIGKILL=no

SuccessExitStatus=0

[Install]
WantedBy=multi-user.target

EOF
```

#####  4.2.3 服务启动

```
systemctl daemon-reload
systemctl enable minio
systemctl start minio
systemctl status minio
```

出现以下日志说明配置成功

![](/images\minio\run.png)

#### 4.3 ngnix负载均衡

##### 4.3.1 docker-compose部署ngnix

```yaml
version: "3.8"
services:
    # ngnix反向代理
    nginx-proxy:
        restart: always
        image: nginx
        volumes:
            - "./ngnix/conf/nginx.conf:/etc/nginx/nginx.conf"
            - "./ngnix/ssl:/root/app/ssl"
            - "./ngnix/logs:/var/log/nginx"
            - "./ngnix/html:/usr/share/nginx/html"
```

##### 4.3.2 修改ngnix配置文件

修改/ngnix/conf/nginx.conf配置文件

```yaml
worker_processes  9;  ## Default: 1
worker_rlimit_nofile 8192;
events {
  worker_connections  4096;  ## Default: 1024
}

http{
charset utf-8;
upstream minio-server {
server 192.168.75.3:9000 weight=25 max_fails=2 fail_timeout=30s;
server 192.168.75.4:9000 weight=25 max_fails=2 fail_timeout=30s;
server 192.168.75.5:9000 weight=25 max_fails=2 fail_timeout=30s;
}
server {
listen 80;
server_name localhost;
charset utf-8;
location /{
proxy_pass http://minio-server/;
}
}}
```

重启ngnix，访问[http:192.168.75.5](http:192.168.75.5)

![](/images\minio\minio-ngnix.png)

#### 五：注意事项

- 分布式Minio里所有的节点需要有同样的access秘钥和secret秘钥，这样这些节点才能建立联接。为了实现这个，**建议** 在执行minio server命令之前，在所有节点上先将access秘钥和secret秘钥export成环境变量`MINIO_ROOT_USER` 和 `MINIO_ROOT_PASSWORD`。
- **MinIO 可创建每组4到16个磁盘组成的纠删码集合。所以你提供的磁盘总数必须是其中一个数字的倍数。**
- MinIO会根据给定的磁盘总数或者节点总数选择最大的纠删码集合大小，确保统一分布，即每个节点参与每个集合的磁盘数量相等。
- **每个对象被写入一个EC集合中，因此该对象分布在不超过16个磁盘上。**
- **建议运行分布式MinIO设置的所有节点都是同构的，即相同的操作系统，相同数量的磁盘和相同的网络互连。**
- 分布式Minio使用干净的目录，里面没有数据。你也可以与其他程序共享磁盘，这时候只需要把一个子目录单独给MinIO使用即可。例如，你可以把磁盘挂在到`/export`下, 然后把`/export/data`作为参数传给MinIO server即可。
- 下面示例里的IP仅供示例参考，你需要改成你真实用到的IP和文件夹路径。
- 分布式Minio里的节点时间差不能超过15分钟，你可以使用[NTP](http://www.ntp.org/) 来保证时间一致。
- `MINIO_DOMAIN`环境变量应该定义并且导出,以支持bucket DNS style。
- 在Windows下运行分布式Minio处于实验阶段，请悠着点使用。















